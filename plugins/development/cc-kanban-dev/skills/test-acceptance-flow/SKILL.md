---
name: test-acceptance-flow
description: 根据用户输入的需求设计完整测试验收流程并执行验证。评估当前项目采用的测试方式（单元测试、UI 测试、浏览器/E2E 等），在用户未明确指定时基于项目现状做最小必要验证。适用于功能交付前验收、回归检查或「如何测」不明确时的测试设计。
---

# 测试验收流程设计与验证

当用户提出**验收需求**（如「怎么验证这个功能」「帮我设计测试」「验收一下刚才的改动」）或需要**交付前确认**时，按本流程设计验收方案并执行验证。用户未明确指定测试形式时，先评估项目再选择**最小必要**的验证方式。

## 何时使用

- 用户描述需求后要求设计或执行验收/测试
- 用户问「怎么测」「如何验收」
- 完成功能开发后需要确认是否满足预期
- 需要评估项目该用单元测试、UI 测试还是浏览器/E2E 测试

若用户已明确指定（如「写 Vitest 单测」「用 Playwright 跑 E2E」），直接按指定方式执行，不必强制重做评估。

---

## 第一步：从需求中提取验收标准

根据用户描述整理出可验证的**验收点**：

| 输出 | 做法 |
|------|------|
| 验收场景列表 | 每个场景：**前置条件 + 操作步骤 + 预期结果** |
| 优先级 | 必须通过 / 建议通过 / 可选；先验证必须项 |
| 边界与异常 | 空数据、错误输入、权限/路径不存在等是否需覆盖 |

若需求较模糊，先列出你的理解（「我理解的验收点如下…」），再请用户确认或补充。

---

## 第二步：评估项目当前测试能力

在用户**未明确指定**测试方式时，先分析项目再决定用哪种验证手段，原则是**最小必要**：能用手动清单解决的不用写自动化，能用现有框架的不新加一整套。

### 2.1 快速检查项

- **package.json**：是否有 `test`、`test:unit`、`test:e2e`、`vitest`、`jest`、`playwright`、`cypress` 等脚本与依赖。
- **项目形态**：纯前端 SPA / Electron 桌面 / Node 服务等 → 决定是否需要启动完整应用、是否可用浏览器自动化（如 MCP cursor-ide-browser）。
- **现有测试文件**：是否存在 `**/*.test.ts`、`**/*.spec.ts`、`**/__tests__/**`、`e2e/**` 等。

### 2.2 选择验证方式（决策顺序）

1. **用户已指定方式**（如「跑单测」「用浏览器点一遍」）→ 按指定执行。
2. **项目已有对应测试**（如已有 Vitest）→ 优先运行现有测试，再按验收点补测或补充用例。
3. **项目无测试框架**→ 不做「为验收临时上一套单元/E2E 框架」；采用：
   - **验收清单 + 手动步骤**：按「操作 → 预期」写出清单，你或用户按步骤执行并勾选；
   - 若环境允许且关键路径明确，可用 **MCP 浏览器**（如 cursor-ide-browser）做少量关键路径验证，并记录结果。
4. **Electron/桌面应用**：通常无头 E2E 成本高；优先「关键流程清单 + 本地启动应用手动验证」或仅浏览器可及部分用 MCP 验证。

总结：**除非用户主动要求，否则以「验收清单 + 最小可执行验证」为主**，不强行引入单元/UI/E2E 框架。

---

## 第三步：输出验收方案

用统一结构输出，便于执行与回溯：

```markdown
## 验收方案

### 验收场景（按优先级）
- [ ] **P0 - 场景名**：前置条件 → 步骤 → 预期结果
- [ ] **P1 - ...**
- [ ] **P2 - ...**

### 验证方式
- 选用方式：（手动清单 / 现有单测 / 现有 E2E / MCP 浏览器关键路径 / 组合）
- 理由：（一句话，如：项目无测试框架，采用手动验收清单）

### 执行计划
- 先执行：…
- 再执行：…
```

---

## 第四步：执行验证并记录结果

- **手动清单**：逐步执行，每项标注 ✅/❌ 并记录实际结果（若失败，简要说明现象）。
- **现有单测/E2E**：运行对应 npm 脚本，贴出通过/失败与失败用例信息。
- **MCP 浏览器**：按「打开页面 → 操作 → 检查结果」执行，记录通过与否与截图/文案等关键信息。

执行完后输出：

```markdown
## 验收结果
- 通过：场景列表
- 未通过：场景 + 实际结果与预期差异
- 未执行/跳过：场景 + 原因
- 建议：后续可补充的测试（如可加单测、可加 E2E）— 仅建议，不强制
```

---

## 流程小结

1. **解析需求** → 提取验收场景与优先级。
2. **评估项目** → 看 package.json、现有测试、项目形态；用户未指定时选最小必要验证方式。
3. **输出方案** → 验收场景 + 验证方式 + 执行计划。
4. **执行验证** → 按方案跑清单/单测/E2E/浏览器，记录通过与失败。
5. **结果汇总** → 通过/未通过/未执行 + 可选后续建议。

---

## 与「开发需求上下文」的衔接

若同一轮对话中先用了 `prepare-dev-request-context` 做实现，其「验收标准与边界」可直接作为本技能的输入；实现完成后调用本技能，用该标准设计并执行验收，形成闭环。

---

## 示例：需求过简时

**用户**：「刚才加的导出功能验收一下。」

1. **验收点**：从实现中推断——如「点击导出 → 选择格式/路径 → 文件生成且内容正确」；若不确定，先列出「我理解的验收点：…」再执行。
2. **评估**：本项目无 test 脚本 → 采用**手动验收清单**（或若导出后可在浏览器内验证，可配合 MCP 做一步检查）。
3. **方案**：P0 点击导出并选择 JSON → 得到文件且内容含当前看板/列/卡片；P1 空看板导出不报错；P2 取消操作无残留文件。
4. **执行**：按清单在已启动应用中操作，记录每项 ✅/❌。
5. **结果**：列出通过/未通过，并可选建议「后续可为导出逻辑加单测」。
